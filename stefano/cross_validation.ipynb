{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the nn class **Sequential** to model a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the single target network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:48.039674Z",
     "start_time": "2018-04-29T15:45:46.586434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import load_script\n",
    "from params import *\n",
    "from custom_layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:48.086364Z",
     "start_time": "2018-04-29T15:45:48.065870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:48.583592Z",
     "start_time": "2018-04-29T15:45:48.088414Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset,target=load_script.load_dataset(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:48.754805Z",
     "start_time": "2018-04-29T15:45:48.585273Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset,test_target=load_script.load_dataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:48.768848Z",
     "start_time": "2018-04-29T15:45:48.756513Z"
    }
   },
   "outputs": [],
   "source": [
    "target=target.long()\n",
    "test_target=test_target.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:48.828631Z",
     "start_time": "2018-04-29T15:45:48.814246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 7.3101e+01  7.3109e+01  7.2001e+01  ...   6.4324e+01  6.5037e+01  6.5048e+01\n",
       " 5.0706e+00  5.9728e+00  4.1829e+00  ...  -3.1212e+00 -2.7500e+00 -2.3117e+00\n",
       " 5.3022e+01  5.3706e+01  5.2293e+01  ...   4.5319e+01  4.5553e+01  4.6292e+01\n",
       "                ...                   â‹±                   ...                \n",
       " 1.3597e+01  1.3734e+01  1.3298e+01  ...   1.0306e+01  1.0556e+01  1.0504e+01\n",
       " 2.3973e+01  2.3983e+01  2.2980e+01  ...   2.2531e+01  2.2226e+01  2.2265e+01\n",
       " 9.5851e+00  9.5892e+00  8.4953e+00  ...   8.9079e+00  9.0392e+00  8.8203e+00\n",
       "[torch.FloatTensor of size 28x50]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([316, 28, 50])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:49.133752Z",
     "start_time": "2018-04-29T15:45:49.109222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean=train_dataset.mean(0).view(1,28,-1)\n",
    "std=train_dataset.std(0).view(1,28,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:45:49.557152Z",
     "start_time": "2018-04-29T15:45:49.525799Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset=(train_dataset-mean)/std\n",
    "test_dataset=(test_dataset-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ThreeLayers(nn.Module):\n",
    "    \n",
    "    num_my_conv_layers=3\n",
    "    num_linear_layers=2\n",
    "    \n",
    "    def __init__(self,params):\n",
    "        super(ThreeLayers,self).__init__()\n",
    "        \n",
    "        self.params=params\n",
    "        \n",
    "        layers=[]\n",
    "        for i in range(self.num_my_conv_layers): \n",
    "            layers+=MyConv1D(*self.params[i]).layers\n",
    "        \n",
    "        layers.append(Flatten())\n",
    "        layers.append(nn.Linear(*self.params[self.num_my_conv_layers]))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(*self.params[self.num_my_conv_layers+1]))\n",
    "        \n",
    "        self.sequential=nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.sequential(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:56:27.249573Z",
     "start_time": "2018-04-29T15:56:27.073138Z"
    }
   },
   "outputs": [],
   "source": [
    "class Train:\n",
    "    ''' Class to train a network\n",
    "    \n",
    "    Usage example:\n",
    "    net_type=ThreeLayers\n",
    "    optimizer_type=optim.Adam\n",
    "    criterion_type=nn.CrossEntropyLoss\n",
    "    network_params=NetworkParams(linear_filters=[200,2])\n",
    "    optimizer_params=OptimizerParams()\n",
    "    train_params=TrainParams(max_epoch=400)\n",
    "\n",
    "\n",
    "    params=Params(net_type,optimizer_type,criterion_type,network_params=network_params,\n",
    "                  optimizer_params=optimizer_params,train_params=train_params,)\n",
    "\n",
    "    train=Train()\n",
    "    train(params)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,cross_validation=True):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self,params,repetitions=5):\n",
    "        epochs=[]\n",
    "        errors_max=[]\n",
    "        errors_mean=[]\n",
    "        for i in range(repetitions):\n",
    "            for param in params.network.parameters():\n",
    "                param.data.normal_(0, params.train_params.weights_initialization)\n",
    "            print('Repetition',i)\n",
    "            epoch,error_max,error_mean=self.train_test_network(params)\n",
    "            epochs.append(epoch)\n",
    "            errors_max.append(error_max)\n",
    "            errors_mean.append(error_mean)\n",
    "        \n",
    "        return epochs,errors_max,errors_mean\n",
    "    \n",
    "    \n",
    "    def train_test_network(self,params):\n",
    "    \n",
    "        errors_train=[]\n",
    "        errors_test=[]\n",
    "        \n",
    "        \n",
    "        for epoch in tqdm(range(params.train_params.max_epoch)):\n",
    "            \n",
    "            total_loss,output_train,error_train=self.train_epoch(params)\n",
    "            output_test,error_test=self.test_epoch(params)\n",
    "        \n",
    "        \n",
    "            errors_train.append(error_train)\n",
    "            errors_test.append(error_test)\n",
    "            \n",
    "            if epoch%10==0 and params.verbose:\n",
    "                print('Epoch:',epoch,'Loss:',total_loss,'Correct:',str(error_train*100)[:5]+\"%\",\n",
    "                     'Correct test:',str(error_test*100)[:5]+\"%\")\n",
    "                \n",
    "        if params.plot:\n",
    "            \n",
    "            print('Performance:',np.mean(errors_test[300:]))\n",
    "            plt.plot(list(range(epoch+1)),errors_train,label='Errors train')\n",
    "            plt.plot(list(range(epoch+1)) ,errors_test,label='Errors test')\n",
    "            \n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "                 \n",
    "        return epoch,np.max(errors_test),np.mean(errors_test[300:])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train_epoch(self,params):\n",
    "        \n",
    "        # Set training True\n",
    "        params.network.train(True)\n",
    "        \n",
    "        # Randomize training dataset\n",
    "        if params.train_params.randomize_training_dataset:\n",
    "            random_permutation=torch.randperm(train_dataset.shape[0])\n",
    "        else:\n",
    "            random_permutation=torch.arange(train_dataset.shape[0])\n",
    "\n",
    "        train_dataset_shuffled=train_dataset[random_permutation]\n",
    "        target_shuffled=target[random_permutation]\n",
    "        \n",
    "        \n",
    "        # Iterate on the dataset\n",
    "        total_loss=0\n",
    "        output_target=torch.zeros(target_shuffled.shape[0])\n",
    "        for b in range(0,train_dataset_shuffled.shape[0],params.train_params.mini_batch_size):\n",
    "\n",
    "            train_element=train_dataset_shuffled.narrow(0,b,params.train_params.mini_batch_size)\n",
    "            target_element=target_shuffled.narrow(0,b,params.train_params.mini_batch_size)\n",
    "\n",
    "            params.optimizer.zero_grad()\n",
    "\n",
    "            out=params.network(train_element)\n",
    "            output_target[b:b+params.train_params.mini_batch_size]=(out[:,1]>out[:,0]).data\n",
    "\n",
    "            loss=params.criterion(out,target_element)\n",
    "            loss.backward()\n",
    "            params.optimizer.step()\n",
    "            total_loss+=loss.data[0]\n",
    "            \n",
    "        error_train=np.sum(list(output_target.long()==target_shuffled.data))/target.shape[0]    \n",
    "        \n",
    "        return total_loss,output_target,error_train\n",
    "    \n",
    "    def test_epoch(self,params):\n",
    "        params.network.train(False)\n",
    "        output_test=torch.zeros(test_target.shape[0])\n",
    "        out=params.network.forward(test_dataset)\n",
    "        output_test=(out[:,1]>out[:,0]).data.long()\n",
    "        error_test=np.sum(list(output_test==test_target.data))/test_target.shape[0]\n",
    "        \n",
    "        return output_test,error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation:\n",
    "    \n",
    "    def __init__(self,k=4):\n",
    "        self._k=k\n",
    "        self._kfold=KFold(n_splits=self.k,shuffle=True)\n",
    "        for train,test in self._kfold.split(train_dataset):\n",
    "            print(train,test)\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def k(self):\n",
    "        return self._k\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net_type=ThreeLayers\n",
    "optimizer_type=optim.Adam\n",
    "criterion_type=nn.CrossEntropyLoss\n",
    "network_params=NetworkParams(linear_filters=[200,2])\n",
    "optimizer_params=OptimizerParams()\n",
    "train_params=TrainParams(max_epoch=400)\n",
    "\n",
    "\n",
    "params=Params(net_type,optimizer_type,criterion_type,network_params=network_params,\n",
    "              optimizer_params=optimizer_params,train_params=train_params,)\n",
    "\n",
    "train=Train()\n",
    "train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
