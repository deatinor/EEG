{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the nn class **Sequential** to model a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the single target network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import load_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset,target=load_script.load_dataset(train=True,single_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset,test_target=load_script.load_dataset(train=False,single_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SingleOutput(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleOutput,self).__init__()\n",
    "\n",
    "        self.conv1=nn.Conv1d(28,14,5)\n",
    "        self.full1=nn.Linear(14*46,100)\n",
    "        self.full2=nn.Linear(100,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool1d(F.relu(self.conv1(x)),1)\n",
    "        x=x.view(-1)\n",
    "        x=F.relu(self.full1(x.view(-1,14*46)))\n",
    "        x=F.sigmoid(self.full2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1.1961029171943665 Correct: 50.0% Correct test: 47.0%\n",
      "Epoch: 10 Loss: 0.9653738290071487 Correct: 63.60% Correct test: 51.0%\n",
      "Epoch: 20 Loss: 0.8787717968225479 Correct: 68.03% Correct test: 51.0%\n",
      "Epoch: 30 Loss: 0.8168325871229172 Correct: 71.20% Correct test: 50.0%\n",
      "Epoch: 40 Loss: 0.765731155872345 Correct: 73.10% Correct test: 53.0%\n",
      "Epoch: 50 Loss: 0.721690908074379 Correct: 75.63% Correct test: 54.0%\n",
      "Epoch: 60 Loss: 0.6846473664045334 Correct: 77.84% Correct test: 54.0%\n",
      "Epoch: 70 Loss: 0.6523829400539398 Correct: 79.43% Correct test: 54.0%\n",
      "Epoch: 80 Loss: 0.6226917058229446 Correct: 80.69% Correct test: 55.0%\n",
      "Epoch: 90 Loss: 0.5947512835264206 Correct: 82.91% Correct test: 56.0%\n",
      "Epoch: 100 Loss: 0.5691540762782097 Correct: 84.17% Correct test: 56.0%\n",
      "Epoch: 110 Loss: 0.5452124699950218 Correct: 85.12% Correct test: 56.0%\n",
      "Epoch: 120 Loss: 0.5195794776082039 Correct: 87.34% Correct test: 58.0%\n",
      "Epoch: 130 Loss: 0.49239061027765274 Correct: 88.29% Correct test: 56.0%\n",
      "Epoch: 140 Loss: 0.4664881303906441 Correct: 89.55% Correct test: 54.0%\n",
      "Epoch: 150 Loss: 0.4796089679002762 Correct: 88.29% Correct test: 56.0%\n",
      "Epoch: 160 Loss: 0.4263487607240677 Correct: 90.50% Correct test: 56.0%\n",
      "Epoch: 170 Loss: 0.4106209948658943 Correct: 90.50% Correct test: 59.0%\n",
      "Epoch: 180 Loss: 0.4126140996813774 Correct: 90.82% Correct test: 58.0%\n",
      "Epoch: 190 Loss: 0.39008213579654694 Correct: 90.82% Correct test: 59.0%\n",
      "Epoch: 200 Loss: 0.3604712039232254 Correct: 92.40% Correct test: 60.0%\n",
      "Epoch: 210 Loss: 0.34266842156648636 Correct: 93.03% Correct test: 60.0%\n",
      "Epoch: 220 Loss: 0.3925238475203514 Correct: 89.55% Correct test: 61.0%\n",
      "Epoch: 230 Loss: 0.3109135627746582 Correct: 93.03% Correct test: 61.0%\n",
      "Epoch: 240 Loss: 0.30589843541383743 Correct: 93.67% Correct test: 61.0%\n",
      "Epoch: 250 Loss: 0.35705458372831345 Correct: 90.82% Correct test: 60.0%\n",
      "Epoch: 260 Loss: 0.269966296851635 Correct: 93.98% Correct test: 62.0%\n",
      "Epoch: 270 Loss: 0.27269457653164864 Correct: 94.62% Correct test: 61.0%\n",
      "Epoch: 280 Loss: 0.2968154475092888 Correct: 93.98% Correct test: 59.0%\n",
      "Epoch: 290 Loss: 0.23544508963823318 Correct: 95.88% Correct test: 62.0%\n",
      "Epoch: 300 Loss: 0.2291402816772461 Correct: 95.25% Correct test: 63.0%\n",
      "Epoch: 310 Loss: 0.21281351149082184 Correct: 96.83% Correct test: 63.0%\n",
      "Epoch: 320 Loss: 0.21814138814806938 Correct: 96.51% Correct test: 61.0%\n",
      "Epoch: 330 Loss: 0.19246383383870125 Correct: 97.78% Correct test: 63.0%\n",
      "Epoch: 340 Loss: 0.18301718682050705 Correct: 97.78% Correct test: 63.0%\n",
      "Epoch: 350 Loss: 0.17923184111714363 Correct: 97.78% Correct test: 62.0%\n",
      "Epoch: 360 Loss: 0.17253485694527626 Correct: 98.10% Correct test: 65.0%\n",
      "Epoch: 370 Loss: 0.1596279926598072 Correct: 98.41% Correct test: 64.0%\n",
      "Epoch: 380 Loss: 0.15193568170070648 Correct: 98.41% Correct test: 65.0%\n",
      "Epoch: 390 Loss: 0.1506049446761608 Correct: 99.36% Correct test: 65.0%\n",
      "Epoch: 400 Loss: 0.13740587048232555 Correct: 99.36% Correct test: 65.0%\n",
      "Epoch: 410 Loss: 0.13343942165374756 Correct: 99.05% Correct test: 65.0%\n",
      "Epoch: 420 Loss: 0.12879641726613045 Correct: 99.68% Correct test: 65.0%\n",
      "Epoch: 430 Loss: 0.1212499737739563 Correct: 99.68% Correct test: 65.0%\n",
      "Epoch: 440 Loss: 0.11525142565369606 Correct: 99.36% Correct test: 65.0%\n",
      "Epoch: 450 Loss: 0.11045444011688232 Correct: 99.68% Correct test: 65.0%\n",
      "Epoch: 460 Loss: 0.10638479329645634 Correct: 100.0% Correct test: 65.0%\n",
      "Epoch: 470 Loss: 0.1033377144485712 Correct: 100.0% Correct test: 65.0%\n",
      "Epoch: 480 Loss: 0.09791279956698418 Correct: 100.0% Correct test: 65.0%\n",
      "Epoch: 490 Loss: 0.09307932294905186 Correct: 100.0% Correct test: 65.0%\n",
      "Epoch: 500 Loss: 0.08958536386489868 Correct: 100.0% Correct test: 65.0%\n",
      "Epoch: 510 Loss: 0.08644180186092854 Correct: 100.0% Correct test: 65.0%\n",
      "Epoch: 520 Loss: 0.0835955310612917 Correct: 100.0% Correct test: 64.0%\n",
      "Epoch: 530 Loss: 0.08082434721291065 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 540 Loss: 0.07714455761015415 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 550 Loss: 0.07386474497616291 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 560 Loss: 0.07118071243166924 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 570 Loss: 0.06896222475916147 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 580 Loss: 0.06612723134458065 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 590 Loss: 0.06397811975330114 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 600 Loss: 0.061971889808773994 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 610 Loss: 0.05973723530769348 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 620 Loss: 0.05740724503993988 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 630 Loss: 0.05566812586039305 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 640 Loss: 0.05389561876654625 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 650 Loss: 0.05228998977690935 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 660 Loss: 0.05042311083525419 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 670 Loss: 0.048589556477963924 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 680 Loss: 0.04721273574978113 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 690 Loss: 0.04559175577014685 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 700 Loss: 0.044090897776186466 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 710 Loss: 0.04272275138646364 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 720 Loss: 0.041470861062407494 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 730 Loss: 0.03998787235468626 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 740 Loss: 0.03884042240679264 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 750 Loss: 0.03767805267125368 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 760 Loss: 0.03645779099315405 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 770 Loss: 0.03529017232358456 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 780 Loss: 0.03430716460570693 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 790 Loss: 0.03331510163843632 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 800 Loss: 0.03233133163303137 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 810 Loss: 0.03143365075811744 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 820 Loss: 0.03058207407593727 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 830 Loss: 0.02974453428760171 Correct: 100.0% Correct test: 67.0%\n",
      "Epoch: 840 Loss: 0.028916343580931425 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 850 Loss: 0.02817316399887204 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 860 Loss: 0.027449918445199728 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 870 Loss: 0.026734369806945324 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 880 Loss: 0.026067822240293026 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 890 Loss: 0.025396577082574368 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 900 Loss: 0.024770020972937346 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 910 Loss: 0.024164946749806404 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 920 Loss: 0.023575644474476576 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 930 Loss: 0.023057664278894663 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 940 Loss: 0.022531992755830288 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 950 Loss: 0.02200254937633872 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 960 Loss: 0.021497291512787342 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 970 Loss: 0.021015648264437914 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 980 Loss: 0.020552340894937515 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 990 Loss: 0.020117543637752533 Correct: 100.0% Correct test: 66.0%\n",
      "Epoch: 1000 Loss: 0.01969784265384078 Correct: 100.0% Correct test: 66.0%\n"
     ]
    }
   ],
   "source": [
    "net=SingleOutput()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "criterion=nn.MSELoss()\n",
    "mini_batch_size=79\n",
    "\n",
    "for epoch in range(1001):\n",
    "    \n",
    "    total_loss=0\n",
    "    output_target=torch.zeros(target.shape[0])\n",
    "    for b in range(0,train_dataset.shape[0],mini_batch_size):\n",
    "        \n",
    "        \n",
    "        train_element=train_dataset.narrow(0,b,mini_batch_size)\n",
    "#         train_element=train_element.view(1,28,-1)\n",
    "        \n",
    "        target_element=target.narrow(0,b,mini_batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         print(train_element.shape)\n",
    "        out=net(train_element)\n",
    "#         print(out)\n",
    "        output_target[b:b+mini_batch_size]=(out>0.5).data\n",
    "#         print(out)\n",
    "#         print(target_element)\n",
    "        loss=criterion(out,target_element)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.data[0]\n",
    "        \n",
    "    output_test=torch.zeros(test_target.shape[0])\n",
    "    out=net(test_dataset)\n",
    "#         print(out)\n",
    "    output_test=(out>0.5).data.type(torch.FloatTensor)\n",
    "        \n",
    "    \n",
    "#     print(type(output_test))\n",
    "        \n",
    "    error_train=np.sum(list(output_target==target.data))/target.shape[0]\n",
    "    error_test=np.sum(list(output_test[:,0]==test_target.data))/test_target.shape[0]\n",
    "    if epoch%10==0:\n",
    "        print('Epoch:',epoch,'Loss:',total_loss,'Correct:',str(error_train*100)[:5]+\"%\",\n",
    "             'Correct test:',str(error_test*100)[:5]+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
